{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering, explored with Semantic Kernel and Azure OpenAI\n",
    "\n",
    "To quickly get started, follow these steps:\n",
    "\n",
    "1. Install [Polyglot notebooks extension](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode) in VSCode.\n",
    "2. [Create a new Azure OpenAI service (or use an existing OpenAI service)](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-studio#prerequisites).\n",
    "3. [Deploy the `gpt-35-turbo` and `text-embeddings-ada-002` models](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#working-with-models).\n",
    "4. [Create an Azure Cognitive Search instance and enable the Semantic Search capability](https://learn.microsoft.com/en-us/azure/search/semantic-search-overview#enable-semantic-search).\n",
    "5. Copy the `.env.example` file from the parent folder to `dotnet/.env` and paste the corresponding values from the resources you provisioned in the earlier steps.\n",
    "6. Click on `Run All`.\n",
    "\n",
    "\n",
    "> You will need an [.Net 7 SDK](https://dotnet.microsoft.com/en-us/download) and [Polyglot](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode) to get started with this notebook using .Net Interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "## What is Prompt Engineering?\n",
    "Prompt engineering is an iterative approach for crafting and refining prompts to enhance interactions with Large Language Models (LLMs). Mastery of prompt engineering is key to unlocking the full potential of LLMs in various applications. This has been pivotal in achieving advanced use cases in Microsoft Copilots.\n",
    "\n",
    "This notebook serves as your go-to resource for effective prompt engineering techniques.\n",
    "\n",
    "### Best Practices: Insights from Azure OpenAI\n",
    "\n",
    "#### Be Specific and Descriptive\n",
    "Craft your prompts to be both specific and descriptive to minimize ambiguity. Using analogies or metaphors can aid in making the prompts more understandable and relatable to the model.\n",
    "\n",
    "#### Be Repetitive\n",
    "- **Repeat**: Reiterate key instructions to ensure clarity and focus in the model's output.\n",
    "- **Order Matters**: The sequence in which you present instructions can influence the modelâ€™s response due to its recency bias.\n",
    "\n",
    "#### Space Efficiency\n",
    "- **Token Limitations**: Be aware of the token limits for the model you are invoking.\n",
    "- **Data Formats**: Opt for tabular formats over JSON for greater space efficiency.\n",
    "- **White Space**: Use space judiciously, as each extra space counts as a token and can limit the model's performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Get Started\n",
    "\n",
    "We will be utilizing **Semantic Kernel** to orchestrate interactions with the `gpt-35-turbo` model, which is deployed on **Azure OpenAI** for brevity. Alternatively, you can also use the **Azure OpenAI SDK** for model orchestration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Kernel to Interact with Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies and import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: dotenv.net, 3.1.2\"\n",
    "dotenv.net.DotEnv.Load();\n",
    "var env = dotenv.net.DotEnv.Read();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 1.0.0-beta1\"\n",
    "#r \"nuget: Microsoft.SemanticKernel.Connectors.Memory.AzureCognitiveSearch, 1.0.0-beta1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.Connectors.AI.OpenAI;\n",
    "using Microsoft.SemanticKernel.Text;\n",
    "using Microsoft.Extensions.Logging;\n",
    "using Microsoft.Extensions.Logging.Abstractions;\n",
    "using System.IO;\n",
    "using System.Text.Json;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the kernel using Azure OpenAI Chat completion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "ILoggerFactory miyagiLoggerFactory = NullLoggerFactory.Instance;\n",
    "var kernel = Kernel.Builder\n",
    "    .WithLoggerFactory(miyagiLoggerFactory)\n",
    "\n",
    "    .WithAzureChatCompletionService(\n",
    "        env[\"AZURE_OPENAI_CHAT_MODEL\"],\n",
    "        env[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        env[\"AZURE_OPENAI_API_KEY\"]\n",
    "    )\n",
    "        \n",
    "    .Build();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
